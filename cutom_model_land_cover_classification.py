# -*- coding: utf-8 -*-
"""EuroSAT land cover classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RzBMyOssu96IUt1zCP4MzZC1iF9QzeSw
"""

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import os
import zipfile
import matplotlib.image as mpimg
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

local_zip = '/content/drive/MyDrive/train_data.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/drive/MyDrive/train_data')
local_zip = '/content/drive/MyDrive/valid_data.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/drive/MyDrive/valid_data')
local_zip = '/content/drive/MyDrive/test_data.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/drive/MyDrive/test_data')
zip_ref.close()

# Directory with our different classes training pictures :
train_AnnualCrop_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/AnnualCrop')

train_Forest_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/Forest')

train_HerbaceousVegetation_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/HerbaceousVegetation')

train_Highway_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/Highway')

train_Industrial_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/Industrial')

train_Pasture_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/Pasture')

train_PermanentCrop_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/PermanentCrop')

train_Residential_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/Residential')

train_River_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/River')

train_SeaLake_dir = os.path.join('/content/drive/MyDrive/train_data/train_data/SeaLake')


# Directory with our different classes validation pictures :
valid_AnnualCrop_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/AnnualCrop')

valid_Forest_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/Forest')

valid_HerbaceousVegetation_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/HerbaceousVegetation')

valid_Highway_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/Highway')

valid_Industrial_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/Industrial')

valid_Pasture_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/Pasture')

valid_PermanentCrop_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/PermanentCrop')

valid_Residential_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/Residential')

valid_River_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/River')

valid_SeaLake_dir = os.path.join('/content/drive/MyDrive/valid_data/valid_data/SeaLake')


# Directory with our different classes testing pictures :
test_AnnualCrop_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/AnnualCrop')

test_Forest_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/Forest')

test_HerbaceousVegetation_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/HerbaceousVegetation')

test_Highway_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/Highway')

test_Industrial_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/Industrial')

test_Pasture_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/Pasture')

test_PermanentCrop_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/PermanentCrop')

test_Residential_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/Residential')

test_River_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/River')

test_SeaLake_dir = os.path.join('/content/drive/MyDrive/test_data/test_data/SeaLake')


print('total training AnnualCrop images:', len(os.listdir(train_AnnualCrop_dir)))
print('total training Forest images:', len(os.listdir(train_Forest_dir)))
print('total training HerbaceousVegetation images:', len(os.listdir(train_HerbaceousVegetation_dir)))
print('total training Highway images:', len(os.listdir(train_Highway_dir)))
print('total training Industrial images:', len(os.listdir(train_Industrial_dir)))
print('total training Pasture images:', len(os.listdir(train_Pasture_dir)))
print('total training PermanentCrop images:', len(os.listdir(train_PermanentCrop_dir)))
print('total training Residential images:', len(os.listdir(train_Residential_dir)))
print('total training River images:', len(os.listdir(train_River_dir)))
print('total training SeaLake images:', len(os.listdir(train_SeaLake_dir)))


print('total validation AnnualCrop images:', len(os.listdir(valid_AnnualCrop_dir)))
print('total validation Forest images:', len(os.listdir(valid_Forest_dir)))
print('total validation HerbaceousVegetation images:', len(os.listdir(valid_HerbaceousVegetation_dir)))
print('total validation Highway images:', len(os.listdir(valid_Highway_dir)))
print('total validation Industrial images:', len(os.listdir(valid_Industrial_dir)))
print('total validation Pasture images:', len(os.listdir(valid_Pasture_dir)))
print('total validation PermanentCrop images:', len(os.listdir(valid_PermanentCrop_dir)))
print('total validation Residential images:', len(os.listdir(valid_Residential_dir)))
print('total validation River images:', len(os.listdir(valid_River_dir)))
print('total validation SeaLake images:', len(os.listdir(valid_SeaLake_dir)))


print('total testing AnnualCrop images:', len(os.listdir(test_AnnualCrop_dir)))
print('total testing Forest images:', len(os.listdir(test_Forest_dir)))
print('total testing HerbaceousVegetation images:', len(os.listdir(test_HerbaceousVegetation_dir)))
print('total testing Highway images:', len(os.listdir(test_Highway_dir)))
print('total testing Industrial images:', len(os.listdir(test_Industrial_dir)))
print('total testing Pasture images:', len(os.listdir(test_Pasture_dir)))
print('total testing PermanentCrop images:', len(os.listdir(test_PermanentCrop_dir)))
print('total testing Residential images:', len(os.listdir(test_Residential_dir)))
print('total testing River images:', len(os.listdir(test_River_dir)))
print('total testing SeaLake images:', len(os.listdir(test_SeaLake_dir)))


img = mpimg.imread('/content/drive/MyDrive/train_data/train_data/AnnualCrop/AnnualCrop_1.jpg')
print(img.shape)
imgplot = plt.imshow(img)


#defining our custom CNN model architecture:
model = keras.Sequential([
    # Note the input shape is the desired size of the image 64x64 with 3 bytes color
    # This is the first convolution
    keras.layers.Conv2D(16, (3,3), strides=(2,2), padding='Same', activation='relu', input_shape=(64,64,3)),
    keras.layers.MaxPooling2D(2,2),
    keras.layers.Conv2D(32, (3,3), strides=(2,2), padding='Same', activation='relu'),
    keras.layers.MaxPooling2D(2,2),
    keras.layers.Conv2D(64, (3,3), strides=(2,2), padding='Same', activation='relu'),
    keras.layers.MaxPooling2D(2,2),
    keras.layers.Flatten(),
    keras.layers.Dense(512, activation='relu'),
    # We have 10 output neuron because we have 10 classes. It will contain a value from 0-9
    keras.layers.Dense(10, activation='softmax')
])

model.summary()


# We will use the data augmentation to avoid the overfitting problem:
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
      rescale=1/255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')
validation_datagen = ImageDataGenerator(rescale=1/255)
# Flow training images in batches of 128 using train_datagen generator
# flow_from_directory=Takes the path to a directory & generates batches of augmented data.
train_generator = train_datagen.flow_from_directory(
        '/content/drive/MyDrive/train_data/train_data',  # This is the source directory for training images
        target_size=(64, 64),  # All images will be resized to 64x64
        batch_size=256, # Size of the batches of data (default: 32).
        class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(
        '/content/drive/MyDrive/valid_data/valid_data',  
        target_size=(64, 64),  
        batch_size=32,
        class_mode='categorical')


#compile the model:
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Adamax
model.compile(
    loss = 'categorical_crossentropy',
    optimizer = Adam(lr=0.001) ,
    metrics = ['accuracy']
)


history = model.fit(
    train_generator,
    epochs = 50,
    validation_data = validation_generator
)


# Plot the loss and accuracy curves for training and validation to know if we overfitting or not:
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
plt.plot(acc,label='Training accuracy')
plt.plot(val_acc,label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.show()
plt.plot(loss,label='Training Loss')
plt.plot(val_loss,label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()


#evaluate the model on the validation data:
results = model.evaluate(validation_generator, verbose=0)
print("test loss, test acc:", results)


#We will use other classification metrics like confusion_matrix, f1_score, recall_score, precision_score :
from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix, classification_report

y_pred=model.predict(validation_generator)

y_pred_modi = np.argmax(y_pred, axis=1)

print(confusion_matrix(validation_generator.classes, y_pred_modi))

print(classification_report(validation_generator.classes, y_pred_modi))

recall_score(validation_generator.classes, y_pred_modi, average='micro')

precision_score(validation_generator.classes, y_pred_modi, average='micro')

f1_score(validation_generator.classes, y_pred_modi, average='micro')


#saving the model:
from keras.models import load_model
model.save('model_file.h5')

my_model = load_model('model_file.h5')


# predicting on the testing data:

test_datagen = ImageDataGenerator()
test_generator = test_datagen.flow_from_directory(
        '/content/drive/MyDrive/test_data/test_data',  
        target_size=(64, 64),  
        class_mode='categorical')

predictions = my_model.predict(test_generator)

predictions_modi = np.argmax(predictions, axis=1)

for i, j in enumerate(predictions_modi[:20]):
    print("Actual_classe: {}".format(test_generator.classes[i]), "Predicted_classe: {}".format(j))
